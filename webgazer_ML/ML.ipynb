{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihan/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 280ms/step - loss: 1.9404 - val_loss: 1.9172 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8895 - val_loss: 1.8696 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.8397 - val_loss: 1.8210 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8097 - val_loss: 1.7755 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.7536 - val_loss: 1.7333 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.6973 - val_loss: 1.6931 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.6946 - val_loss: 1.6549 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.6497 - val_loss: 1.6184 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.6126 - val_loss: 1.5850 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.5418 - val_loss: 1.5540 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.5521 - val_loss: 1.5225 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.4933 - val_loss: 1.4910 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.5078 - val_loss: 1.4610 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.4779 - val_loss: 1.4322 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.4371 - val_loss: 1.4029 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4184 - val_loss: 1.3753 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4507 - val_loss: 1.3489 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3385 - val_loss: 1.3223 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.3322 - val_loss: 1.2945 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.2764 - val_loss: 1.2630 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.2946 - val_loss: 1.2320 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.1813 - val_loss: 1.2030 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3001 - val_loss: 1.1764 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.2914 - val_loss: 1.1517 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.2541 - val_loss: 1.1273 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.2051 - val_loss: 1.1021 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.1874 - val_loss: 1.0786 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.1662 - val_loss: 1.0551 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.1375 - val_loss: 1.0326 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.1399 - val_loss: 1.0112 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.1090 - val_loss: 0.9910 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.1073 - val_loss: 0.9751 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.1364 - val_loss: 0.9634 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.0311 - val_loss: 0.9622 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.0744 - val_loss: 0.9653 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.0300 - val_loss: 0.9623 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.0316 - val_loss: 0.9574 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.9946 - val_loss: 0.9542 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.0119 - val_loss: 0.9460 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.0193 - val_loss: 0.9297 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.0105 - val_loss: 0.9112 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.9918 - val_loss: 0.8911 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9884 - val_loss: 0.8654 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.0079 - val_loss: 0.8394 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.9257 - val_loss: 0.8191 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.9525 - val_loss: 0.8009 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.0076 - val_loss: 0.7863 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.9104 - val_loss: 0.7753 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9851 - val_loss: 0.7666 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.9036 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step\n",
      "Mean Squared Error: 4.815307140350342\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "ground_truth_path = '/home/zihan/bounding_box/annotated_gaze/002_tobii_afunc_appear3.csv.csv'\n",
    "predictions_path = '/home/zihan/bounding_box/annotated_gaze_webgazer/002_webgazer_tobiitime_afunc_appear3.csv.csv'\n",
    "ground_truth = pd.read_csv(ground_truth_path)\n",
    "predictions = pd.read_csv(predictions_path)\n",
    "\n",
    "# Assuming the geometry column is correctly positioned\n",
    "ground_truth = ground_truth.iloc[:, :-3]  # adjust the slice if necessary\n",
    "predictions = predictions.iloc[:, :-3]    # adjust the slice if necessary\n",
    "\n",
    "# Melt the DataFrames to long format\n",
    "ground_truth = pd.melt(ground_truth, id_vars=ground_truth.columns[:18], value_vars=ground_truth.columns[18:], var_name='token_gt', value_name='Value')\n",
    "predictions = pd.melt(predictions, id_vars=predictions.columns[:7], value_vars=predictions.columns[7:], var_name='token_pred', value_name='Value')\n",
    "\n",
    "# Function to extract coordinates from geometry column\n",
    "def extract_coordinates(df):\n",
    "    coords = df['geometry'].str.extract(r'POINT \\(([-\\d\\.]+) ([-\\d\\.]+)\\)')\n",
    "    df['x'], df['y'] = coords[0].astype(float), coords[1].astype(float)\n",
    "    return df.drop(columns=['geometry'])\n",
    "\n",
    "# Apply the function\n",
    "ground_truth = extract_coordinates(ground_truth)\n",
    "predictions = extract_coordinates(predictions)\n",
    "\n",
    "# Drop missing values and reset index\n",
    "ground_truth.dropna(inplace=True)\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "predictions.dropna(inplace=True)\n",
    "predictions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "ground_truth[['x', 'y']] = scaler.fit_transform(ground_truth[['x', 'y']])\n",
    "predictions[['x', 'y']] = scaler.transform(predictions[['x', 'y']])\n",
    "\n",
    "# Function to create sequences for LSTM input\n",
    "def create_sequences(data, sequence_length=10):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        xs.append(data.iloc[i:(i + sequence_length)][['x', 'y']].values)\n",
    "        ys.append(data.iloc[i + sequence_length][['x', 'y']].values)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Prepare training datasets\n",
    "sequence_length = 10\n",
    "X, y = create_sequences(ground_truth, sequence_length)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to float32 for model compatibility\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "\n",
    "# Define a simpler LSTM model with stronger regularization\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    LSTM(32, kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2)  # Outputs x and y\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping and learning rate reduction on plateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Prepare test data\n",
    "X_test, y_test = create_sequences(predictions, sequence_length)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Predict using the LSTM model\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "# Adjust the predictions DataFrame to match the sequence length reduction\n",
    "predictions_adjusted = predictions.iloc[sequence_length:sequence_length + len(predicted_values)].reset_index(drop=True)\n",
    "predictions_adjusted['predicted_x'], predictions_adjusted['predicted_y'] = predicted_values[:, 0], predicted_values[:, 1]\n",
    "\n",
    "# Add ground truth tokens to the predictions_adjusted DataFrame for comparison\n",
    "predictions_adjusted['ground_truth_token'] = ground_truth['token_gt'].iloc[sequence_length:sequence_length + len(predicted_values)].values\n",
    "\n",
    "# Save the corrected predictions\n",
    "predictions_adjusted.to_csv('corrected_predictions_LSTM.csv', index=False)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predicted_values)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihan/anaconda3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.6586 - val_loss: 1.2092\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6108 - val_loss: 1.1912\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6363 - val_loss: 1.1797\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6298 - val_loss: 1.1728\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6041 - val_loss: 1.1675\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5686 - val_loss: 1.1618\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5672 - val_loss: 1.1568\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5755 - val_loss: 1.1509\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5108 - val_loss: 1.1470\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5780 - val_loss: 1.1448\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4625 - val_loss: 1.1414\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4364 - val_loss: 1.1382\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5034 - val_loss: 1.1351\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4960 - val_loss: 1.1334\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4324 - val_loss: 1.1334\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5681 - val_loss: 1.1326\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4557 - val_loss: 1.1297\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5250 - val_loss: 1.1256\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4850 - val_loss: 1.1207\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4162 - val_loss: 1.1159\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Mean Squared Error: 1.042952060699463\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "ground_truth_path = '/home/zihan/bounding_box/annotated_gaze/002_tobii_afunc_appear3.csv.csv'\n",
    "predictions_path = '/home/zihan/bounding_box/annotated_gaze_webgazer/002_webgazer_tobiitime_afunc_appear3.csv.csv'\n",
    "ground_truth = pd.read_csv(ground_truth_path)\n",
    "predictions = pd.read_csv(predictions_path)\n",
    "\n",
    "# Assuming the geometry column is correctly positioned\n",
    "ground_truth = ground_truth.iloc[:, :-3]  # adjust the slice if necessary\n",
    "predictions = predictions.iloc[:, :-3]    # adjust the slice if necessary\n",
    "\n",
    "# Melt the DataFrames to long format\n",
    "ground_truth = pd.melt(ground_truth, id_vars=ground_truth.columns[:18], value_vars=ground_truth.columns[18:], var_name='token_gt', value_name='Value')\n",
    "predictions = pd.melt(predictions, id_vars=predictions.columns[:7], value_vars=predictions.columns[7:], var_name='token_pred', value_name='Value')\n",
    "\n",
    "# Function to extract coordinates from geometry column\n",
    "def extract_coordinates(df):\n",
    "    coords = df['geometry'].str.extract(r'POINT \\(([-\\d\\.]+) ([-\\d\\.]+)\\)')\n",
    "    df['x'], df['y'] = coords[0].astype(float), coords[1].astype(float)\n",
    "    return df.drop(columns=['geometry'])\n",
    "\n",
    "# Apply the function\n",
    "ground_truth = extract_coordinates(ground_truth)\n",
    "predictions = extract_coordinates(predictions)\n",
    "\n",
    "# Drop missing values and reset index\n",
    "ground_truth.dropna(inplace=True)\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "predictions.dropna(inplace=True)\n",
    "predictions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "ground_truth[['x', 'y']] = scaler.fit_transform(ground_truth[['x', 'y']])\n",
    "predictions[['x', 'y']] = scaler.transform(predictions[['x', 'y']])\n",
    "\n",
    "# Prepare the features and targets\n",
    "sequence_length = 10\n",
    "def create_sequences(data, target, sequence_length=10):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        xs.append(data.iloc[i:(i + sequence_length)][['x', 'y']].values)\n",
    "        ys.append(target.iloc[i + sequence_length][['x', 'y']].values)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "X_train, y_train = create_sequences(ground_truth, ground_truth, sequence_length)\n",
    "X_test, y_test = create_sequences(predictions, ground_truth, sequence_length)  # Use ground_truth for y_test to simulate correction\n",
    "\n",
    "# Reshape data to fit the CNN input\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(32, kernel_size=2, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2)  # Outputs x and y\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Convert data to float32 for model compatibility\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict using the CNN model\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "# Adjust the predictions DataFrame to match the sequence length reduction\n",
    "predictions_adjusted = predictions.iloc[sequence_length:sequence_length + len(predicted_values)].reset_index(drop=True)\n",
    "predictions_adjusted['predicted_x'], predictions_adjusted['predicted_y'] = predicted_values[:, 0], predicted_values[:, 1]\n",
    "\n",
    "# Function to find nearest ground truth token based on Euclidean distance\n",
    "def find_nearest_ground_truth(predicted_point, ground_truth):\n",
    "    distances = np.sqrt((ground_truth['x'] - predicted_point[0])**2 + (ground_truth['y'] - predicted_point[1])**2)\n",
    "    min_index = np.argmin(distances)\n",
    "    return ground_truth.iloc[min_index]['token_gt']\n",
    "\n",
    "# Map predictions to nearest ground truth tokens\n",
    "predictions_adjusted['corrected_token'] = predictions_adjusted.apply(lambda row: find_nearest_ground_truth([row['predicted_x'], row['predicted_y']], ground_truth), axis=1)\n",
    "\n",
    "# Add ground truth tokens to the predictions_adjusted DataFrame for comparison\n",
    "predictions_adjusted['ground_truth_token'] = ground_truth['token_gt'].iloc[sequence_length:sequence_length + len(predicted_values)].values\n",
    "\n",
    "# Save the corrected predictions\n",
    "predictions_adjusted.to_csv('corrected_predictions_CNNs.csv', index=False)\n",
    "\n",
    "# Optionally evaluate the model\n",
    "mse = mean_squared_error(y_test, predicted_values)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
